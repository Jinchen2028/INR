train_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./data/DIV2K/train/HR
      repeat: 20
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled
    args:
      inp_size: 48
      scale_max: 4
      augment: true
      sample_q: 2304
  batch_size: 16

val_dataset:
  dataset:
    name: image-folder
    args:
      root_path: ./data/DIV2K/val/HR
      first_k: 10
      repeat: 160
      cache: in_memory
  wrapper:
    name: sr-implicit-downsampled
    args:
      inp_size: 48
      scale_max: 4
      sample_q: 2304
  batch_size: 16

data_norm:
  inp: {sub: [0.5], div: [0.5]}
  gt: {sub: [0.5], div: [0.5]}

model:
  name: ultrasr
  args:
#    in_features: 2
#    out_features: 3
#    hidden_features: 265
#    hidden_layers: 2
    encoder_spec:
      name: edsr-baseline
      args:
        no_upsampling: true
    imnet_spec:
      name: res_mlp
      args:
        in_dim: 2
#        hidden_features: 256
#        out_features: 3
#        hidden_layers: 5
#        first_omega_0: 5.0
#        hidden_omega_0: 5.0
#        scale: 10.0
        out_dim: 3
        hidden_list: [256, 256, 256, 256]
#    pos_encode: true
#resume: /home/jinchen/TEST/liif/save/Train-edsr-liif/epoch-best.pth
optimizer:
  name: adam
  args:
    lr: 1.e-4
epoch_max: 1000

#scheduler:
#    type: CosineAnnealingRestartLR
#    periods: [ 1000 ]
#    restart_weights: [ 1 ]
#    eta_min: !!float 1e-6

scheduler:
    type: MultiStepLR
    milestones: [200, 400, 600, 800]
    gamma: 0.5

#  scheduler:
#    type: MultiStepLR
#    milestones: [ 200000, 400000, 600000, 800000 ]
#    gamma: 0.5

epoch_val: 1
epoch_save: 100
